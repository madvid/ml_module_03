{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 02 : Multivariate Linear Regression\n",
    "\n",
    "*Summary: Building on what you did on the previous modules you will extend the linear\n",
    "regression to handle more than one features. Then you will see how to build polynomial\n",
    "models and how to detect overfitting.*\n",
    "\n",
    "## Notions of the module\n",
    "Multivariate linear hypothesis, multivariate linear gradient descent, polynomial models. \n",
    "Training and test sets, overfitting.\n",
    "\n",
    "## Useful Ressources  \n",
    "  \n",
    "You are strongly advise to use the following resource:\n",
    "[Machine Learning MOOC - Stanford](https://www.coursera.org/learn/machine-learning/home/week/2)  \n",
    "Here are the sections of the MOOC that are relevant for today's exercises: \n",
    "\n",
    "### Week 2: \n",
    "\n",
    "**Multivariate Linear Regression:**\n",
    "* Multiple Features (Video + Reading)\n",
    "* Gradient Descent for Multiple Variables (Video + Reading)\n",
    "* Gradient Descent in Practice I- Feature Scaling (Video + Reading)\n",
    "* Gradient Descent in Practice II- Learning Rate (Video + Reading)\n",
    "* Features and Polynomial Regression (Video + Reading)\n",
    "* Review (Reading + Quiz)\n",
    "\n",
    "## General rules\n",
    "See directly the 42Paris intra subject or the corresponding repository on the [github of 42AI](https://github.com/42-AI/bootcamp_machine-learning)\n",
    "\n",
    "\n",
    "## Helper\n",
    "\n",
    "Ensure that you have the right Python interpreter (at least 3.7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "```git push --quiet github``` to push on github when working from the vogsphere repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 00 - Multivariate Hypothesis - Iterative Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ex00.prediction import simple_predict\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(1,13).reshape((4,3))\n",
    "print(\"# Example 0:\")\n",
    "theta1 = np.array([[5],[0],[0],[0]])\n",
    "pred = simple_predict(x, theta1)\n",
    "# Ouput:\n",
    "# array([[5.],[ 5.],[ 5.],[ 5.]])\n",
    "# Do you understand why y_hat contains only 5’s here?\n",
    "expected_pred = np.array([[5.],[ 5.],[ 5.],[ 5.]])\n",
    "print(\"my prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "\n",
    "\n",
    "print(\"\\n# Example 1:\")\n",
    "theta2 = np.array([[0],[1],[0],[0]])\n",
    "pred = simple_predict(x, theta2)\n",
    "# Output:\n",
    "# array([[ 1.],[ 4.],[ 7.],[ 10.]])\n",
    "# Do you understand why y_hat == x[:,0] here?\n",
    "expected_pred = np.array([[ 1.],[ 4.],[ 7.],[ 10.]])\n",
    "print(\"my prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(25), expected_pred.reshape(1, -1))\n",
    "\n",
    "\n",
    "print(\"\\n# Example 2:\")\n",
    "theta3 = np.array([[-1.5],[0.6],[2.3],[1.98]])\n",
    "pred = simple_predict(x, theta3)\n",
    "# Output:\n",
    "# array([[ 9.64],[ 24.28],[ 38.92],[ 53.56]])\n",
    "expected_pred = np.array([[ 9.64],[ 24.28],[ 38.92],[ 53.56]])\n",
    "print(\"my prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(25), expected_pred.reshape(1, -1))\n",
    "\n",
    "\n",
    "print(\"\\n# Example 3:\")\n",
    "theta4 = np.array([[-3],[1],[2],[3.5]])\n",
    "pred = simple_predict(x, theta4)\n",
    "# Output:\n",
    "# array([[12.5],[ 32. ],[ 51.5],[ 71. ]])\n",
    "expected_pred = np.array([[12.5],[ 32. ],[ 51.5],[ 71. ]])\n",
    "print(\"my prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(25), expected_pred.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 01 - Mulltivariate hypothesis - Vectorized Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my prediction:            [[5. 5. 5. 5.]]\n",
      "expected prediction:      [[5. 5. 5. 5.]]\n",
      "my prediction:            [[ 1.  4.  7. 10.]]\n",
      "expected prediction:      [[ 1.  4.  7. 10.]]\n",
      "my prediction:            [[ 9.64 24.28 38.92 53.56]]\n",
      "expected prediction:      [[ 9.64 24.28 38.92 53.56]]\n",
      "my prediction:            [[12.5 32.  51.5 71. ]]\n",
      "expected prediction:      [[12.5 32.  51.5 71. ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ex01.prediction import predict_\n",
    "\n",
    "x = np.arange(1,13).reshape((4,-3))\n",
    "# Example 0:\n",
    "theta1 = np.array([[5],[ 0],[ 0],[ 0]])\n",
    "pred = predict_(x, theta1)\n",
    "# Ouput:\n",
    "# array([[5.],[ 5.],[ 5.],[ 5.]])\n",
    "# Do you understand why y_hat contains only 5’s here?\n",
    "expected_pred = np.array([[5.],[ 5.],[ 5.],[ 5.]])\n",
    "print(\"my prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(25), expected_pred.reshape(1, -1))\n",
    "\n",
    "# Example 1:\n",
    "theta2 = np.array([[0],[ 1],[ 0],[ 0]])\n",
    "pred = predict_(x, theta2)\n",
    "# Output:\n",
    "# array([[ 1.],[ 4.],[ 7.],[ 10.]])\n",
    "# Do you understand why y_hat == x[:,0] here?\n",
    "expected_pred = np.array([[1.],[ 4.],[ 7.],[ 10.]])\n",
    "print(\"my prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(25), expected_pred.reshape(1, -1))\n",
    "\n",
    "# Example 2:\n",
    "theta3 = np.array([[-1.5],[ 0.6],[ 2.3],[ 1.98]])\n",
    "pred = predict_(x, theta3)\n",
    "# Output:\n",
    "# array([[ 9.64],[ 24.28],[ 38.92],[ 53.56]])\n",
    "expected_pred = np.array([[ 9.64],[ 24.28],[ 38.92],[ 53.56]])\n",
    "print(\"my prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(25), expected_pred.reshape(1, -1))\n",
    "\n",
    "# Example 3:\n",
    "theta4 = np.array([[-3],[ 1],[ 2],[ 3.5]])\n",
    "pred = predict_(x, theta4)\n",
    "# Output:\n",
    "# array([[12.5],[ 32. ],[ 51.5],[ 71. ]])\n",
    "expected_pred = np.array([[12.5],[ 32. ],[ 51.5],[ 71. ]])\n",
    "print(\"my prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(25), expected_pred.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 02 - Vectorized Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Example 0:\n",
      "my loss:             2.142857142857143\n",
      "expected loss:       2.1428571428571437\n",
      "# Example 1:\n",
      "my loss:             0.0\n",
      "expected loss:       0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ex02.loss import loss_\n",
    "\n",
    "X = np.array([[0],[ 15],[ -9],[ 7],[ 12],[ 3],[ -21]])\n",
    "Y = np.array([[2],[ 14],[ -13],[ 5],[ 12],[ 4],[ -19]])\n",
    "\n",
    "print(\"# Example 0:\")\n",
    "loss = loss_(X, Y)\n",
    "expected_loss = 2.1428571428571436\n",
    "print(\"my loss: \".ljust(20), loss)\n",
    "print(\"expected loss: \".ljust(20), expected_loss)\n",
    "\n",
    "print(\"# Example 1:\")\n",
    "loss = loss_(X, X)\n",
    "expected_loss = 0.0\n",
    "print(\"my loss: \".ljust(20), loss)\n",
    "print(\"expected loss: \".ljust(20), expected_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 03 - Multivariate Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Example 0:\n",
      "my gradient:         [[ -33.71428571  -37.35714286  183.14285714 -393.        ]]\n",
      "expected gradient:   [[ -33.71428571  -37.35714286  183.14285714 -393.        ]]\n",
      "\n",
      "# Example 1:\n",
      "my gradient:         [[ -0.71428571   0.85714286  23.28571429 -26.42857143]]\n",
      "expected gradient:   [[ -0.71428571   0.85714286  23.28571429 -26.42857143]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ex03.gradient import gradient\n",
    "\n",
    "x = np.array([[ -6, -7, -9],\n",
    "              [ 13, -2, 14],\n",
    "              [ -7, 14, -1],\n",
    "              [ -8, -4, 6],\n",
    "              [ -5, -9, 6],\n",
    "              [ 1, -5, 11],\n",
    "              [ 9, -11, 8]])\n",
    "y = np.array([[2],[ 14],[ -13],[ 5],[ 12],[ 4],[ -19]])\n",
    "\n",
    "print(\"# Example 0:\")\n",
    "theta1 = np.array([[0],[ 3],[ 0.5],[ -6]])\n",
    "grad = gradient(x, y, theta1)\n",
    "# Output:\n",
    "expected_grad = np.array([[ -33.71428571],[ -37.35714286],[ 183.14285714],[ -393.]])\n",
    "print(\"my gradient:\".ljust(20), grad.reshape(1, -1))\n",
    "print(\"expected gradient:\".ljust(20), expected_grad.reshape(1, -1))\n",
    "\n",
    "print(\"\\n# Example 1:\")\n",
    "theta2 = np.array([[0],[ 0],[ 0],[ 0]])\n",
    "grad = gradient(x, y, theta2)\n",
    "# Output:\n",
    "expected_grad = np.array([[ -0.71428571],[ 0.85714286],[ 23.28571429],[ -26.42857143]])\n",
    "print(\"my gradient:\".ljust(20), grad.reshape(1, -1))\n",
    "print(\"expected gradient:\".ljust(20), expected_grad.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 04 - Multivariate Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Example 0:\n",
      "initial value of theta:\n",
      " [[42.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "After training value of theta:           [[41.99888822  0.97792316  0.77923161 -1.20768386]]\n",
      "After training expected value of theta:  [[41.99888822  0.97792316  0.77923161 -1.20768386]]\n",
      "\n",
      "# Example 1:\n",
      "my prediction:       [[ 19.59925884  -2.80037055 -25.19999994 -47.59962933]]\n",
      "expected prediction: [[ 19.5992  -2.8003 -25.1999 -47.5996]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ex04.fit import fit_\n",
    "from utils.prediction import predict_\n",
    "\n",
    "\n",
    "x = np.array([[0.2, 2., 20.], [0.4, 4., 40.], [0.6, 6., 60.], [0.8, 8., 80.]])\n",
    "y = np.array([[19.6], [-2.8], [-25.2], [-47.6]])\n",
    "theta = np.array([[42.], [1.], [1.], [1.]])\n",
    "\n",
    "\n",
    "print(\"# Example 0:\")\n",
    "nw_theta = fit_(x, y, theta, alpha = 0.0005, max_iter=42000)\n",
    "# Output:\n",
    "expected_theta = np.array([[41.99],[0.97], [0.77], [-1.20]])\n",
    "print(\"initial value of theta:\\n\", theta)\n",
    "print(\"After training value of theta:\".ljust(40), nw_theta.reshape(1, -1))\n",
    "print(\"After training expected value of theta:\".ljust(40), nw_theta.reshape(1, -1))\n",
    "\n",
    "\n",
    "print(\"\\n# Example 1:\")\n",
    "pred = predict_(x, nw_theta)\n",
    "# Output:\n",
    "# np.array([[19.5992..], [-2.8003..], [-25.1999..], [-47.5996..]])\n",
    "expected_pred = np.array([[19.5992], [-2.8003], [-25.1999], [-47.5996]])\n",
    "print(\"my prediction:\".ljust(20), pred.reshape(1,-1))\n",
    "print(\"expected prediction:\".ljust(20), expected_pred.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 05 - Multivariate Linear Regression With Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Example 0:\n",
      "my prediction:       [[  8.  48. 323.]]\n",
      "expected prediction: [[  8.  48. 323.]]\n",
      "\n",
      "# Example 1:\n",
      "my loss elem:        [[  225.     0. 11025.]]\n",
      "expected loss elem:  [[  225.     0. 11025.]]\n",
      "\n",
      "# Example 2:\n",
      "my loss:        1875.0\n",
      "expected loss:  1875.0\n",
      "\n",
      "# Example 3:\n",
      "my theta after training:\n",
      " [[ 1.81883792e+01  2.76697788e+00 -3.74782024e-01  1.39219585e+00\n",
      "   1.74138279e-02]]\n",
      "expected theta after training:\n",
      " [[ 1.8188e+01  2.7670e+00 -3.7400e-01  1.3920e+00  1.7000e-02]]\n",
      "\n",
      "# Example 4:\n",
      "my prediction:\n",
      " [[ 23.41720822  47.48924883 218.06563769]]\n",
      "expected prediction:\n",
      " [[ 23.417  47.489 218.065]]\n",
      "\n",
      "# Example 5:\n",
      "my loss elem:\n",
      " [[0.1740627  0.26086676 0.00430831]]\n",
      "expected loss elem:\n",
      " [[0.174 0.26  0.004]]\n",
      "\n",
      "# Example 6:\n",
      "my loss:        0.07320629376956732\n",
      "expected loss:  0.0732\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ex05.mylinearregression import MyLinearRegression as MyLR\n",
    "\n",
    "X = np.array([[1., 1., 2., 3.], [5., 8., 13., 21.], [34., 55., 89., 144.]])\n",
    "Y = np.array([[23.], [48.], [218.]])\n",
    "mylr = MyLR([[1.], [1.], [1.], [1.], [1]])\n",
    "\n",
    "print(\"# Example 0:\")\n",
    "pred = mylr.predict_(X)\n",
    "# Output:\n",
    "expected_pred = np.array([[8.], [48.], [323.]])\n",
    "print(\"my prediction:\".ljust(20), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(20), pred.reshape(1, -1))\n",
    "\n",
    "\n",
    "print(\"\\n# Example 1:\")\n",
    "loss_e = mylr.loss_elem_(X,Y)\n",
    "# Output:\n",
    "expected_loss_e = np.array([[225.], [0.], [11025.]])\n",
    "print(\"my loss elem:\".ljust(20), loss_e.reshape(1, -1))\n",
    "print(\"expected loss elem:\".ljust(20), expected_loss_e.reshape(1, -1))\n",
    "\n",
    "\n",
    "print(\"\\n# Example 2:\")\n",
    "loss = mylr.loss_(X,Y)\n",
    "# Output:\n",
    "expected_loss = 1875.0\n",
    "print(\"my loss:\".ljust(15), loss)\n",
    "print(\"expected loss:\".ljust(15), expected_loss)\n",
    "\n",
    "\n",
    "print(\"\\n# Example 3:\")\n",
    "mylr.alpha = 1.6e-4\n",
    "mylr.max_iter = 200000\n",
    "mylr.fit_(X, Y)\n",
    "# Output:\n",
    "expected_thetas = np.array([[18.188], [2.767], [-0.374], [1.392], [0.017]])\n",
    "print(\"my theta after training:\\n\", mylr.thetas.reshape(1, -1))\n",
    "print(\"expected theta after training:\\n\", expected_thetas.reshape(1, -1))\n",
    "\n",
    "\n",
    "print(\"\\n# Example 4:\")\n",
    "pred = mylr.predict_(X)\n",
    "# Output:\n",
    "expected_pred = np.array([[23.417], [47.489], [218.065]])\n",
    "print(\"my prediction:\\n\", pred.reshape(1, -1))\n",
    "print(\"expected prediction:\\n\", expected_pred.reshape(1, -1))\n",
    "\n",
    "\n",
    "print(\"\\n# Example 5:\")\n",
    "loss_e = mylr.loss_elem_(X,Y)\n",
    "# Output:\n",
    "expected_loss_e = np.array([[0.174], [0.260], [0.004]])\n",
    "print(\"my loss elem:\\n\", loss_e.reshape(1, -1))\n",
    "print(\"expected loss elem:\\n\", expected_loss_e.reshape(1, -1))\n",
    "\n",
    "print(\"\\n# Example 6:\")\n",
    "loss = mylr.loss_(X,Y)\n",
    "# Output:\n",
    "expected_loss = 0.0732\n",
    "print(\"my loss:\".ljust(15), loss)\n",
    "print(\"expected loss:\".ljust(15), expected_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 06 - Practicing Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/goinfre/mdavid/v_bootcamp/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Converting `np.inexact` or `np.floating` to a dtype is deprecated. The current result is `float64` which is not strictly correct.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True, True, True, True]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('ex06/spacecraft_data.csv')\n",
    "\n",
    "[dt == np.float64 for dt in data.dtypes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 07 - Polynommial models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 08 - Let's Train Polynomial Models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 09 - DataSpliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 10 - Machine Learning for Grown-ups: Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50baabd70a1595a756c74ef7edb7013232b1c3c869f8ef50cd86aea3cdd4dc6d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
