{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 02 : Multivariate Linear Regression\n",
    "\n",
    "*Summary: Building on what you did on the previous modules you will extend the linear\n",
    "regression to handle more than one features. Then you will see how to build polynomial\n",
    "models and how to detect overfitting.*\n",
    "\n",
    "## Notions of the module\n",
    "Multivariate linear hypothesis, multivariate linear gradient descent, polynomial models. \n",
    "Training and test sets, overfitting.\n",
    "\n",
    "## Useful Ressources  \n",
    "  \n",
    "You are strongly advise to use the following resource:\n",
    "[Machine Learning MOOC - Stanford](https://www.coursera.org/learn/machine-learning/home/week/2)  \n",
    "Here are the sections of the MOOC that are relevant for today's exercises: \n",
    "\n",
    "### Week 2: \n",
    "\n",
    "**Multivariate Linear Regression:**\n",
    "* Multiple Features (Video + Reading)\n",
    "* Gradient Descent for Multiple Variables (Video + Reading)\n",
    "* Gradient Descent in Practice I- Feature Scaling (Video + Reading)\n",
    "* Gradient Descent in Practice II- Learning Rate (Video + Reading)\n",
    "* Features and Polynomial Regression (Video + Reading)\n",
    "* Review (Reading + Quiz)\n",
    "\n",
    "## General rules\n",
    "See directly the 42Paris intra subject or the corresponding repository on the [github of 42AI](https://github.com/42-AI/bootcamp_machine-learning)\n",
    "\n",
    "\n",
    "## Helper\n",
    "\n",
    "Ensure that you have the right Python interpreter (at least 3.7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "```git push --quiet github``` to push on github when working from the vogsphere repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEED TO BEFORE START:\n",
    "* execute the script of ex08, because it takes time\n",
    "* execute the script of ex10, because it takes time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 00 - Multivariate Hypothesis - Iterative Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ex00.prediction import simple_predict\n",
    "\n",
    "x = np.arange(1,13).reshape((4,3))\n",
    "print(\"# Example 0:\")\n",
    "theta1 = np.array([[5],[0],[0],[0]])\n",
    "pred = simple_predict(x, theta1)\n",
    "# Ouput:\n",
    "# array([[5.],[ 5.],[ 5.],[ 5.]])\n",
    "# Do you understand why y_hat contains only 5’s here?\n",
    "expected_pred = np.array([[5.],[ 5.],[ 5.],[ 5.]])\n",
    "print(\"my prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "\n",
    "\n",
    "print(\"\\n# Example 1:\")\n",
    "theta2 = np.array([[0],[1],[0],[0]])\n",
    "pred = simple_predict(x, theta2)\n",
    "# Output:\n",
    "# array([[ 1.],[ 4.],[ 7.],[ 10.]])\n",
    "# Do you understand why y_hat == x[:,0] here?\n",
    "expected_pred = np.array([[ 1.],[ 4.],[ 7.],[ 10.]])\n",
    "print(\"my prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(25), expected_pred.reshape(1, -1))\n",
    "\n",
    "\n",
    "print(\"\\n# Example 2:\")\n",
    "theta3 = np.array([[-1.5],[0.6],[2.3],[1.98]])\n",
    "pred = simple_predict(x, theta3)\n",
    "# Output:\n",
    "# array([[ 9.64],[ 24.28],[ 38.92],[ 53.56]])\n",
    "expected_pred = np.array([[ 9.64],[ 24.28],[ 38.92],[ 53.56]])\n",
    "print(\"my prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(25), expected_pred.reshape(1, -1))\n",
    "\n",
    "\n",
    "print(\"\\n# Example 3:\")\n",
    "theta4 = np.array([[-3],[1],[2],[3.5]])\n",
    "pred = simple_predict(x, theta4)\n",
    "# Output:\n",
    "# array([[12.5],[ 32. ],[ 51.5],[ 71. ]])\n",
    "expected_pred = np.array([[12.5],[ 32. ],[ 51.5],[ 71. ]])\n",
    "print(\"my prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(25), expected_pred.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 01 - Mulltivariate hypothesis - Vectorized Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ex01.prediction import predict_\n",
    "\n",
    "x = np.arange(1,13).reshape((4,-3))\n",
    "print(\"# Example 0:\")\n",
    "theta1 = np.array([[5],[ 0],[ 0],[ 0]])\n",
    "pred = predict_(x, theta1)\n",
    "# Ouput:\n",
    "# array([[5.],[ 5.],[ 5.],[ 5.]])\n",
    "# Do you understand why y_hat contains only 5’s here?\n",
    "expected_pred = np.array([[5.],[ 5.],[ 5.],[ 5.]])\n",
    "print(\"my prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(25), expected_pred.reshape(1, -1))\n",
    "\n",
    "print(\"\\n# Example 1:\")\n",
    "theta2 = np.array([[0],[ 1],[ 0],[ 0]])\n",
    "pred = predict_(x, theta2)\n",
    "# Output:\n",
    "# array([[ 1.],[ 4.],[ 7.],[ 10.]])\n",
    "# Do you understand why y_hat == x[:,0] here?\n",
    "expected_pred = np.array([[1.],[ 4.],[ 7.],[ 10.]])\n",
    "print(\"my prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(25), expected_pred.reshape(1, -1))\n",
    "\n",
    "print(\"\\n# Example 2:\")\n",
    "theta3 = np.array([[-1.5],[ 0.6],[ 2.3],[ 1.98]])\n",
    "pred = predict_(x, theta3)\n",
    "# Output:\n",
    "# array([[ 9.64],[ 24.28],[ 38.92],[ 53.56]])\n",
    "expected_pred = np.array([[ 9.64],[ 24.28],[ 38.92],[ 53.56]])\n",
    "print(\"my prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(25), expected_pred.reshape(1, -1))\n",
    "\n",
    "print(\"\\n# Example 3:\")\n",
    "theta4 = np.array([[-3],[ 1],[ 2],[ 3.5]])\n",
    "pred = predict_(x, theta4)\n",
    "# Output:\n",
    "# array([[12.5],[ 32. ],[ 51.5],[ 71. ]])\n",
    "expected_pred = np.array([[12.5],[ 32. ],[ 51.5],[ 71. ]])\n",
    "print(\"my prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(25), expected_pred.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 02 - Vectorized Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ex02.loss import loss_\n",
    "\n",
    "X = np.array([[0],[ 15],[ -9],[ 7],[ 12],[ 3],[ -21]])\n",
    "Y = np.array([[2],[ 14],[ -13],[ 5],[ 12],[ 4],[ -19]])\n",
    "\n",
    "print(\"# Example 0:\")\n",
    "loss = loss_(X, Y)\n",
    "expected_loss = 2.1428571428571436\n",
    "print(\"my loss: \".ljust(20), loss)\n",
    "print(\"expected loss: \".ljust(20), expected_loss)\n",
    "\n",
    "print(\"\\n# Example 1:\")\n",
    "loss = loss_(X, X)\n",
    "expected_loss = 0.0\n",
    "print(\"my loss: \".ljust(20), loss)\n",
    "print(\"expected loss: \".ljust(20), expected_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 03 - Multivariate Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ex03.gradient import gradient\n",
    "\n",
    "x = np.array([[ -6, -7, -9],\n",
    "              [ 13, -2, 14],\n",
    "              [ -7, 14, -1],\n",
    "              [ -8, -4, 6],\n",
    "              [ -5, -9, 6],\n",
    "              [ 1, -5, 11],\n",
    "              [ 9, -11, 8]])\n",
    "y = np.array([[2],[ 14],[ -13],[ 5],[ 12],[ 4],[ -19]])\n",
    "\n",
    "print(\"# Example 0:\")\n",
    "theta1 = np.array([[0],[ 3],[ 0.5],[ -6]])\n",
    "grad = gradient(x, y, theta1)\n",
    "# Output:\n",
    "expected_grad = np.array([[ -33.71428571],[ -37.35714286],[ 183.14285714],[ -393.]])\n",
    "print(\"my gradient:\".ljust(20), grad.reshape(1, -1))\n",
    "print(\"expected gradient:\".ljust(20), expected_grad.reshape(1, -1))\n",
    "\n",
    "print(\"\\n# Example 1:\")\n",
    "theta2 = np.array([[0],[ 0],[ 0],[ 0]])\n",
    "grad = gradient(x, y, theta2)\n",
    "# Output:\n",
    "expected_grad = np.array([[ -0.71428571],[ 0.85714286],[ 23.28571429],[ -26.42857143]])\n",
    "print(\"my gradient:\".ljust(20), grad.reshape(1, -1))\n",
    "print(\"expected gradient:\".ljust(20), expected_grad.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 04 - Multivariate Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ex04.fit import fit_\n",
    "from utils.prediction import predict_\n",
    "\n",
    "\n",
    "x = np.array([[0.2, 2., 20.], [0.4, 4., 40.], [0.6, 6., 60.], [0.8, 8., 80.]])\n",
    "y = np.array([[19.6], [-2.8], [-25.2], [-47.6]])\n",
    "theta = np.array([[42.], [1.], [1.], [1.]])\n",
    "\n",
    "\n",
    "print(\"# Example 0:\")\n",
    "nw_theta = fit_(x, y, theta, alpha = 0.0005, max_iter=42000)\n",
    "# Output:\n",
    "expected_theta = np.array([[41.99],[0.97], [0.77], [-1.20]])\n",
    "print(\"initial value of theta:\".ljust(40), theta.reshape(1,-1))\n",
    "print(\"After training value of theta:\".ljust(40), nw_theta.reshape(1, -1))\n",
    "print(\"After training expected value of theta:\".ljust(40), expected_theta.reshape(1, -1))\n",
    "\n",
    "\n",
    "print(\"\\n# Example 1:\")\n",
    "pred = predict_(x, nw_theta)\n",
    "# Output:\n",
    "# np.array([[19.5992..], [-2.8003..], [-25.1999..], [-47.5996..]])\n",
    "expected_pred = np.array([[19.5992], [-2.8003], [-25.1999], [-47.5996]])\n",
    "print(\"my prediction:\".ljust(20), pred.reshape(1,-1))\n",
    "print(\"expected prediction:\".ljust(20), expected_pred.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 05 - Multivariate Linear Regression With Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ex05.mylinearregression import MyLinearRegression as MyLR\n",
    "\n",
    "X = np.array([[1., 1., 2., 3.], [5., 8., 13., 21.], [34., 55., 89., 144.]])\n",
    "Y = np.array([[23.], [48.], [218.]])\n",
    "mylr = MyLR([[1.], [1.], [1.], [1.], [1]])\n",
    "\n",
    "print(\"# Example 0:\")\n",
    "pred = mylr.predict_(X)\n",
    "# Output:\n",
    "expected_pred = np.array([[8.], [48.], [323.]])\n",
    "print(\"my prediction:\".ljust(20), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(20), pred.reshape(1, -1))\n",
    "\n",
    "\n",
    "print(\"\\n# Example 1:\")\n",
    "loss_e = mylr.loss_elem_(X,Y)\n",
    "# Output:\n",
    "expected_loss_e = np.array([[225.], [0.], [11025.]])\n",
    "print(\"my loss elem:\".ljust(20), loss_e.reshape(1, -1))\n",
    "print(\"expected loss elem:\".ljust(20), expected_loss_e.reshape(1, -1))\n",
    "\n",
    "\n",
    "print(\"\\n# Example 2:\")\n",
    "loss = mylr.loss_(X,Y)\n",
    "# Output:\n",
    "expected_loss = 1875.0\n",
    "print(\"my loss:\".ljust(15), loss)\n",
    "print(\"expected loss:\".ljust(15), expected_loss)\n",
    "\n",
    "\n",
    "print(\"\\n# Example 3:\")\n",
    "mylr.alpha = 1.6e-4\n",
    "mylr.max_iter = 200000\n",
    "mylr.fit_(X, Y)\n",
    "# Output:\n",
    "expected_thetas = np.array([[18.188], [2.767], [-0.374], [1.392], [0.017]])\n",
    "print(\"my theta after training:\".ljust(25), mylr.thetas.reshape(1, -1))\n",
    "print(\"expected theta after training:\".ljust(25), expected_thetas.reshape(1, -1))\n",
    "\n",
    "\n",
    "print(\"\\n# Example 4:\")\n",
    "pred = mylr.predict_(X)\n",
    "# Output:\n",
    "expected_pred = np.array([[23.417], [47.489], [218.065]])\n",
    "print(\"my prediction:\".ljust(25), pred.reshape(1, -1))\n",
    "print(\"expected prediction:\".ljust(25), expected_pred.reshape(1, -1))\n",
    "\n",
    "\n",
    "print(\"\\n# Example 5:\")\n",
    "loss_e = mylr.loss_elem_(X,Y)\n",
    "# Output:\n",
    "expected_loss_e = np.array([[0.174], [0.260], [0.004]])\n",
    "print(\"my loss elem:\".ljust(25), loss_e.reshape(1, -1))\n",
    "print(\"expected loss elem:\".ljust(25), expected_loss_e.reshape(1, -1))\n",
    "\n",
    "print(\"\\n# Example 6:\")\n",
    "loss = mylr.loss_(X,Y)\n",
    "# Output:\n",
    "expected_loss = 0.0732\n",
    "print(\"my loss:\".ljust(15), loss)\n",
    "print(\"expected loss:\".ljust(15), expected_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 06 - Practicing Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the python script directly in in folder ex06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 07 - Polynomial models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ex07.polynomial_model import add_polynomial_features\n",
    "\n",
    "x = np.arange(1,6).reshape(-1, 1)\n",
    "\n",
    "print(\"# Example 0:\")\n",
    "print(add_polynomial_features(x, 0))\n",
    "# Output:\n",
    "# array([[ 1.],\n",
    "#        [ 1.],\n",
    "#        [ 1.],\n",
    "#        [ 1.],\n",
    "#        [ 1.]])\n",
    "\n",
    "print(\"# Example 1:\")\n",
    "print(add_polynomial_features(x, 1))\n",
    "# Output:\n",
    "# array([[ 1],\n",
    "#        [ 2],\n",
    "#        [ 3],\n",
    "#        [ 4],\n",
    "#        [ 5]])\n",
    "\n",
    "print(\"# Example 2:\")\n",
    "print(add_polynomial_features(x, 2))\n",
    "# Output:\n",
    "# array([[ 1,  1],\n",
    "#        [ 2,  4],\n",
    "#        [ 3,  9],\n",
    "#        [ 4, 16],\n",
    "#        [ 5, 25]])\n",
    "\n",
    "print(\"# Example 3:\")\n",
    "print(add_polynomial_features(x, 3))\n",
    "# Output:\n",
    "# array([[ 1,  1,   1],\n",
    "#        [ 2,  4,   8],\n",
    "#        [ 3,  9,  27],\n",
    "#        [ 4, 16,  64],\n",
    "#        [ 5, 25, 125]])\n",
    "\n",
    "print(\"\\n# Example 1:\")\n",
    "print(add_polynomial_features(x, 6))\n",
    "# Output:\n",
    "# array([[ 1,  1,   1,   1,    1,    1],\n",
    "#        [ 2,  4,   8,  16,   32,   64],\n",
    "#        [ 3,  9,  27,  81,  243,  729],\n",
    "#        [ 4, 16,  64, 256, 1024, 4096],\n",
    "#        [ 5, 25, 125, 625, 3125, 15625]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 08 - Let's Train Polynomial Models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the python script directly in in folder ex08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 09 - DataSpliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ex09.data_spliter import data_spliter\n",
    "\n",
    "np.random.seed(42)\n",
    "x1 = np.array([[1],[ 42],[ 300],[ 10],[ 59]])\n",
    "y = np.array([[0],[1],[0],[1],[0]])\n",
    "\n",
    "print(\"# Example 0:\")\n",
    "split = data_spliter(x1, y, 0.8)\n",
    "for arr in split:\n",
    "    print(arr)\n",
    "# Output:\n",
    "# (array([[ 10],\n",
    "#         [ 42],\n",
    "#         [  1],\n",
    "#         [300]]),\n",
    "#  array([[59]]),\n",
    "#  array([[1],\n",
    "#         [1],\n",
    "#         [0],\n",
    "#         [0]]),\n",
    "#  array([[0]]))\n",
    "\n",
    "print(\"\\n# Example 1:\")\n",
    "split = data_spliter(x1, y, 0.5)\n",
    "for arr in split:\n",
    "    print(arr)\n",
    "# Output:\n",
    "#(array([[42],\n",
    "#        [10]]),\n",
    "# array([[ 59],\n",
    "#        [300],\n",
    "#        [ 1]]),\n",
    "#  array([[1],\n",
    "#         [1]]),\n",
    "#  array([[0],\n",
    "#         [0],\n",
    "#         [0]]))\n",
    "x2 = np.array([[  1, 42],\n",
    "               [300, 10],\n",
    "               [ 59,  1],\n",
    "               [300, 59],\n",
    "               [ 10, 42]])\n",
    "y = np.array([[0],[1],[0],[1],[0]])\n",
    "\n",
    "\n",
    "print(\"\\n# Example 2:\")\n",
    "split = data_spliter(x2, y, 0.8)\n",
    "for arr in split:\n",
    "    print(arr)\n",
    "# Output:\n",
    "# (array([[10, 42],\n",
    "#         [59,  1],\n",
    "#         [ 1, 42],\n",
    "#         [300, 10]]),\n",
    "#  array([[300, 59]]),\n",
    "#  array([[0],\n",
    "#         [0],\n",
    "#         [0],\n",
    "#         [1]]),\n",
    "#  array([[1]]))\n",
    "\n",
    "\n",
    "print(\"\\n# Example 3:\")\n",
    "split = data_spliter(x2, y, 0.5)\n",
    "for arr in split:\n",
    "    print(arr)\n",
    "# Output:\n",
    "# (array([[300, 10],\n",
    "#         [  1, 42]]),\n",
    "#  array([[ 10, 42],\n",
    "#         [300, 59],\n",
    "#         [ 59,  1]]),\n",
    "#  array([[1],\n",
    "#         [0]]),\n",
    "#  array([[0],\n",
    "#         [1],\n",
    "#         [0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 10 - Machine Learning for Grown-ups: Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the python scripts directly in in folder ex10"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50baabd70a1595a756c74ef7edb7013232b1c3c869f8ef50cd86aea3cdd4dc6d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
